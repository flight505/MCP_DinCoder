# DinCoder Project Plan & Roadmap

## Roadmap Snapshot
- **Roadmap Version:** 3.0 (Integration Strategy added 2025-10-16)
- **Document Last Updated:** 2025-10-17
- **Current Package Version:** 0.4.2 (Documentation fixes for MCP prompts, published to npm)
- **Next Target Version:** 0.5.0 (Integration Strategy B - Claude Code Plugin)
- **Stories Complete:** 28 / 36 (78%) - Phase 1 & 2 COMPLETE, Integration Phase STARTED ğŸ¯
- **Stories in Progress:** Phase 3 - Integration & Discovery (Strategies B-E)
- **Latest Release Highlights:** v0.4.2 fixes critical documentation issues - MCP prompts are AI workflow orchestrators, not user-typed slash commands!

## Vision Statement
DinCoder is a fully-fledged Spec-Driven Development MCP server optimized for AI coding assistants. Unlike GitHub's CLI-focused Spec Kit, DinCoder delivers the complete Constitution â†’ Specify â†’ Clarify â†’ Plan â†’ Tasks â†’ Implement â†’ Validate workflow as composable MCP tools ready for agents such as Claude Code, Cursor, and GitHub Copilot.

## Current State vs Target State

### Current State (v0.1.20)
- âœ… Core workflow tools (specify, plan, tasks) are live with authentic Spec Kit markdown generation.
- âœ… Quality tools (format, lint, test, security, deps, license) keep repositories healthy.
- âœ… Supporting tools (artifacts, research, git) enable research trails and branch management.
- âœ… Dual transport support: STDIO and Streamable HTTP with Smithery deployment.
- âœ… CI/CD pipeline publishes to npm and Smithery; automated prompt validation exists.
- âš ï¸ Five advanced Spec Kit-style commands (validation, visualization, templates, etc.) are still planned.

### Target State (v1.0.0)
- âœ… Full Spec Kit parity for AI agents (validation, refinement, visualization, contracts).
- âœ… Quality gates and analytics to block incomplete specs and surface trends.
- âœ… Visual diagrams and contract generation directly from artifacts.
- âœ… Template customization, task filtering, and dependency graphs for large projects.
- âœ… Production-grade observability, error recovery, and best-practice guidance.

## Roadmap Phases Overview

| Phase | Version | Goal | Incremental Tools/Features | Timeline | Status |
|-------|---------|------|---------------------------|----------|--------|
| Current | v0.1.x | Smithery deployment & quality tooling foundation | 14 tools | Complete | âœ… |
| Phase 1 | v0.2.0 | Core Spec Kit parity (constitution, clarify, validation) | +7 â†’ 21 tools | Completed 2025-10-16 | âœ… **COMPLETE** |
| Phase 2 | v0.3.0 | Advanced task management (visualize, filter, batch, search, stats) | +5 â†’ 26 tools | Completed 2025-10-16 | âœ… **COMPLETE** |
| Phase 3 | v0.4.0 | Integration Strategy A (MCP Prompts - Universal) | +7 prompts | Completed 2025-10-16 | âœ… **COMPLETE** |
| Phase 3.1 | v0.5.0 | Integration Strategy B (Claude Code Plugin) | Plugin repo | ~1 week | ğŸ“‹ Planned |
| Phase 3.2 | v0.6.0 | Integration Strategy C+D (VS Code + Codex docs) | Documentation | ~1 week | ğŸ“‹ Planned |
| Phase 3.3 | v0.7.0 | Integration Strategy E (Project Templates) | Templates | ~1 week | ğŸ“‹ Planned |
| Phase 4 | v0.8.0 | Advanced features (contracts, templates, metrics, lint) | +6 â†’ 32+ tools | ~3 weeks | ğŸ“‹ Planned |
| Phase 5 | v1.0.0 | Production polish & examples | Refinement | ~2 weeks | ğŸ“‹ Planned |

## Project Status Summary (Last Updated: 2025-10-16)

**Progress:** 28/36 stories complete (78%)

- âœ… **Completed:** Stories 2, 3, 6-16, 24-34 (Phases 1, 2, and 3 - Strategy A COMPLETE!)
- ğŸ“‹ **Planned:** Stories 35-38 (Phase 3.1-3.3 - Integration Strategies B-E)
- ğŸ“‹ **Next Priority:** Story 35 - Claude Code Plugin (Strategy B)

**Phase 3 Achievements (v0.4.0 - Integration & Discovery):**
- âœ… Story 34: MCP Prompts (Strategy A - Universal)
  - 7 workflow prompts: `start_project`, `create_spec`, `generate_plan`, `create_tasks`, `review_progress`, `validate_spec`, `next_tasks`
  - Auto-discovered slash commands in all MCP clients
  - Built-in workflow guidance
  - Cross-platform compatibility (Claude Code, VS Code, Codex, Cursor)
- ğŸ¯ **Result:** Zero-configuration integration across all platforms!

**Phase 2 Achievements (v0.3.0 - Advanced Task Management):**
- âœ… Story 29: Task Visualization (`tasks_visualize`) - Mermaid, Graphviz, ASCII graphs
- âœ… Story 30: Task Filtering (`tasks_filter`) - Smart presets and multi-criteria filtering
- âœ… Story 31: Batch Operations (`tasks_tick_range`) - Range expansion for bulk completion
- âœ… Story 32: Task Search (`tasks_search`) - Fuzzy matching with Levenshtein algorithm
- âœ… Story 33: Task Statistics (`tasks_stats`) - Progress charts and analytics
- ğŸ¯ **Result:** Scalable task management for 50+ task projects!

**Phase 1 Achievements (v0.2.0 - Core Spec Kit Parity):**
- âœ… Story 24: Constitution Tool (`constitution_create`)
- âœ… Story 25: Clarification Tracking (`clarify_add`, `clarify_resolve`, `clarify_list`)
- âœ… Story 26: Spec Validation & Quality Gates (`spec_validate`, `artifacts_analyze`)
- âœ… Story 27: Spec Refinement (`spec_refine`)
- âœ… Story 28: Prerequisites Check (`prereqs_check`)
- ğŸ¯ **Result:** 100% GitHub Spec Kit command parity for AI coding workflows!

**Testing:** 52 tests across unit, integration, and conformance (52 passing, 22 skipped edge cases)

---

## Detailed Story Backlog

Below is a very, very, very detailed project plan rendered as a markdown checklist. It is organized into "stories," each broken down into oneâ€‘storyâ€‘point tasks (every checkbox is small and independently completable by an autonomous coding agent). Where a task's rationale depends on external knowledge, I've cited the official MCP spec, Smithery docs, and GitHub Spec Kit materials; where a task is grounded in the uploaded YouTube transcript, I've cited the transcript.

âœ… Project: Specâ€‘Driven MCP Orchestrator (Streamable HTTP, NPM + Smithery)

Story 0 â€” Load research & extract requirements (video transcript â†’ working notes)

Goal: Read the uploaded YouTube subtitles to ground our understanding of Spec Kit and specâ€‘driven development; distill actionables.

	â€¢	Open the uploaded transcript file and load it into the repo under docs/research/spec-kit-youtube-transcript.txt.  ï¿¼
	â€¢	Create docs/research/spec-kit-notes.md and summarize: Specâ€‘driven vs â€œvibe codingâ€, and why specs serve as the single source of truth.  ï¿¼
	â€¢	Extract the four gated phases (Specify, Plan, Tasks, Implement) with oneâ€‘sentence definitions each.  ï¿¼
	â€¢	Note the CLI ergonomics (initialization creates scripts/templates; branch creation; spec markdown output; â€œneeds clarificationâ€ block).
	â€¢	Record that Spec Kit creates a detailed task list with numbered items, favoring testâ€‘first flow in the template.
	â€¢	Export a concise glossary: â€œspec,â€ â€œplan,â€ â€œtasks,â€ â€œimplement,â€ â€œacceptance scenarios,â€ â€œedge cases,â€ â€œresearch doc,â€ â€œzod schema.â€  ï¿¼
	â€¢	Commit docs/research/spec-kit-notes.md with transcript references.

â¸»

Story 1 â€” Consolidate current state of the art (Spec Kit + MCP + Smithery)

Goal: Pin authoritative sources and pin versions.

	â€¢	Add docs/refs.md listing authoritative references with short annotations (MCP transports; Smithery deployments; Spec Kit repo/blog; MCP TS/Py SDKs).  ï¿¼ ï¿¼ ï¿¼
	â€¢	In docs/refs.md, capture Streamable HTTP essentials (single endpoint; POST + optional SSE; GET SSE; session header; protocol version header).  ï¿¼
	â€¢	Record Smithery requirements (endpoint = /mcp; handle GET/POST/DELETE; optional ?config=<base64>).  ï¿¼
	â€¢	Confirm Spec Kit crossâ€‘agent support (Copilot, Claude Code, Gemini CLI) and CLI bootstrap command.  ï¿¼ ï¿¼
	â€¢	Pin SDK choices: @modelcontextprotocol/sdk (TS) as primary; document Python SDK parity for future ports.  ï¿¼
	â€¢	Commit docs/refs.md.

â¸»

Story 2 â€” Greenfield repo bootstrap & developer workflow âœ…

Goal: Create a clean, boring, reproducible TypeScript workspace.

	â€¢ âœ…	Initialize repo: git init; create main branch; set default Node to >=20.
	â€¢ âœ…	Create package.json with type: "module" and scripts: dev, build, lint, format, test, start:local.
	â€¢ âœ…	Add tsconfig.json (module/moduleResolution: "NodeNext", target: ES2022, strict: true, outDir: dist, rootDir: src). **CRITICAL: Must use NodeNext for MCP SDK compatibility.**
	â€¢ âœ…	Install runtime deps: @modelcontextprotocol/sdk (^1.17.5+), zod, express.  ï¿¼
	â€¢ âœ…	Install dev deps: typescript, tsx, vitest, @vitest/coverage-v8, supertest, @types/node, @types/express, eslint, @eslint/js, typescript-eslint, prettier, tsup.
	â€¢ âœ…	Add .editorconfig (2 spaces, LF, utfâ€‘8).
	â€¢ âœ…	Add .nvmrc with Node LTS; document with README blurb.
	â€¢ âœ…	Configure ESLint: eslint.config.mjs with TS parser, node/globals, import rules.
	â€¢ âœ…	Configure Prettier: prettier.config.cjs.
	â€¢	Add Husky + lint-staged preâ€‘commit (format + eslint on staged).
	â€¢ âœ…	Add LICENSE (MIT) and basic README.md skeleton.
	â€¢ âœ…	Commit as "chore: bootstrap repo".

â¸»

Story 3 â€” Real Spec Kit Integration âœ…

Goal: Transform from mock implementation to authentic Spec-Driven Development orchestrator.

	â€¢ âœ…	Created speckit/detector.ts module for detecting Spec Kit document types from content
	â€¢ âœ…	Created speckit/parser.ts module for parsing Spec Kit markdown to structured JSON
	â€¢ âœ…	Created speckit/templates.ts module with official Spec Kit markdown templates
	â€¢ âœ…	Updated all tools (specify, plan, tasks) to generate real Spec Kit markdown documents
	â€¢ âœ…	Cached official Spec Kit templates locally in templates/speckit/ directory
	â€¢ âœ…	Maintained backward compatibility with JSON format while adding markdown support
	â€¢ âœ…	Tools now generate authentic documents that work with GitHub's SDD methodology
	â€¢ âœ…	Provides clear path: intent â†’ specification â†’ plan â†’ tasks â†’ implementation

â¸»

Story 4 â€” Plan the technical architecture (align to Streamable HTTP & Smithery)

Goal: Produce a concrete plan honoring spec and platform constraints.

	â€¢	Run /plan with constraints: TypeScript, Express, Streamable HTTP, /mcp endpoint, config via ?config=<base64>.  ï¿¼ ï¿¼
	â€¢	Ensure the plan includes: Data model (Zod schemas), research document, and contracts for object types.  ï¿¼
	â€¢	Verify plan calls out session management and MCPâ€‘Protocolâ€‘Version header handling.  ï¿¼
	â€¢	Verify security guidance: Origin validation, local bind guidance, auth.  ï¿¼
	â€¢	Gate: Approve plan; commit specs/000-orchestrator/plan.md.

â¸»

Story 5 â€” Expand tasks with Spec Kit, then normalize to 1â€‘point units

Goal: Generate and curate the granular toâ€‘do list used for implementation.

	â€¢	Run /tasks to generate the actionable backlog.  ï¿¼
	â€¢	Split any large items into smaller 1â€‘point tasks; keep each unit shippable in isolation.  ï¿¼
	â€¢	Ensure early tasks cover environment setup and testâ€‘first where appropriate.  ï¿¼
	â€¢	Commit specs/000-orchestrator/tasks.md as the canonical execution list.

â¸»

Story 6 â€” Implement MCP server skeleton (Streamable HTTP) âœ…

Goal: Build a minimal but specâ€‘compliant server exposing a /mcp endpoint with POST/GET/DELETE.

	â€¢ âœ…	Create src/server/createServer.ts exporting a factory createServer() that wires tools/resources/prompts using the TS SDK.  ï¿¼
	â€¢ âœ…	Create src/http/app.ts with an Express app.
	â€¢ âœ…	Add src/http/transport.ts that wraps StreamableHTTPServerTransport from the TS SDK.  ï¿¼
	â€¢ âœ…	**CRITICAL**: For stateless mode, create new server/transport instances per request. For stateful mode, implement session map with UUID-based session IDs.
	â€¢ âœ…	Implement POST /mcp to accept one JSONâ€‘RPC message per request and either SSE (for streamed responses) or JSON per MCP spec.  ï¿¼
	â€¢ âœ…	Implement GET /mcp to open an SSE stream for serverâ€‘initiated messages; return 405 if not supported.  ï¿¼
	â€¢ âœ…	Implement DELETE /mcp to end a session when Mcp-Session-Id header is provided (if server allows clientâ€‘initiated termination).  ï¿¼
	â€¢ âœ…	Add Mcp-Session-Id issuance on initialization (use crypto.randomUUID()) and enforce header presence on subsequent calls (400 if absent).  ï¿¼
	â€¢ âœ…	Return/accept MCP-Protocol-Version header; default to "2025-03-26" when absent (per spec guidance).  ï¿¼
	â€¢ âœ…	Implement Origin checking and optional auth (bearer/API key) middleware.  ï¿¼
	â€¢ âœ…	Add graceful shutdown (SIGINT/SIGTERM) to close transports. Use res.on('close') to cleanup per-request resources.
	â€¢ âœ…	Write unit tests for POST/GET/DELETE happy paths and error paths using vitest + supertest.
	â€¢ âœ…	Add SSE tests ensuring event framing (data: ...\n\n) correctness and stream close after response.  ï¿¼
	â€¢ âœ…	**Error Handling**: Wrap all handlers in try-catch, log to stderr, return valid JSON-RPC error responses.
	â€¢ âœ…	Commit "feat(server): minimal MCP streamable HTTP endpoint".

â¸»

Story 7 â€” Implement Specâ€‘Driven tools inside the MCP server âœ…

Goal: Expose tools that run Spec Kit phases and parse artifacts so any AI coder can drive SDD through MCP.

	â€¢ âœ…	Tool specify.start: inputs { projectName, agent }; runs specify init <projectName> --ai <agent>; returns path + summary.  ï¿¼
	â€¢ âœ…	Tool specify.describe: inputs { description }; posts /specify <description> into agent session or CLI wrapper; returns generated spec path.  ï¿¼
	â€¢ âœ…	Tool plan.create: inputs { constraintsText }; posts /plan ... to generate plan.md, data model, contracts; returns file paths.  ï¿¼
	â€¢ âœ…	Tool tasks.generate: inputs { scope }; posts /tasks to produce tasks.md; returns structured task objects (id, title, deps).  ï¿¼
	â€¢ âœ…	Tool tasks.tick: mark a task ID as done; persist in tasks.md (idempotent update).  ï¿¼
	â€¢ âœ…	Tool artifacts.read: return normalized JSON for spec/plan/tasks for downstream UIs.
	â€¢ âœ…	Tool research.append: write to the Spec Kit research doc for decisions taken.  ï¿¼
	â€¢ âœ…	Tool git.create_branch: create a working branch for a feature (Spec Kit may do this on init; mirror behavior).  ï¿¼
	â€¢ âœ…	Add robust path sandboxing (only operate under a configured workspace directory).
	â€¢ âœ…	Add timeouts and resource limits when running CLI commands.

â¸»

Story 8 â€” MCP tools for repo hygiene & quality âœ…

Goal: Ensure autonomous agents don't degrade the codebase.

	â€¢ âœ…	Tool quality.format: run Prettier; return diff summary.
	â€¢ âœ…	Tool quality.lint: run ESLint; return problem list JSON.
	â€¢ âœ…	Tool quality.test: run vitest --run --coverage; return pass rate + coverage.
	â€¢ âœ…	Tool quality.security_audit: run npm audit --json; summarize vulnerabilities.
	â€¢ âœ…	Tool quality.deps_update: dryâ€‘run minor updates (e.g., npm outdated summary).
	â€¢ âœ…	Tool quality.license_check: scan dependencies for license compatibility.

â¸»

Story 9 â€” Validation & conformance to MCP spec âœ…

Goal: Prove we follow the letter of the spec.

	â€¢ âœ…	Add JSONâ€‘RPC schema tests for requests/responses.  ï¿¼
	â€¢ âœ…	Add tests for resumability using SSE id and Last-Event-ID headers (server may support replay).  ï¿¼
	â€¢ âœ…	Add a test for rejecting invalid Origin.  ï¿¼
	â€¢ âœ…	Add tests ensuring single endpoint path for POST/GET/DELETE (/mcp).  ï¿¼
	â€¢ âœ…	Verify MCPâ€‘Protocolâ€‘Version negotiation is honored.  ï¿¼
	â€¢ âœ…	Create docs/conformance.md summarizing checks with links to spec sections.  ï¿¼

â¸»

Story 10 â€” Configuration, security & ops âœ…

Goal: Make it safe to run remotely.

	â€¢ âœ…	Parse Smithery ?config=<base64> and map to internal config schema (Zod).  ï¿¼
	â€¢ âœ…	Add CONFIG_ORIGIN_WHITELIST and validate on every request.  ï¿¼
	â€¢ âœ…	Support API key auth via Authorization: Bearer <token> (optional).
	â€¢ âœ…	Integrate structured logging (pino); never leak secrets in logs.
	â€¢ âœ…	Health endpoint GET /healthz (nonâ€‘MCP) with build info.
	â€¢ âœ…	Rate limiting on /mcp (token bucket per IP/session).
	â€¢ âœ…	Add CORS controls (default deny; allow configured origins).
	â€¢ âœ…	Provide Dockerfile (node:22-alpine) with nonâ€‘root user.
	â€¢ âœ…	Add SECURITY.md listing threat model and mitigations (DNS rebinding, auth).  ï¿¼

â¸»

Story 11 â€” Developer ergonomics & examples âœ…

Goal: Smooth adoption.

	â€¢ âœ…	examples/local-client.ts: connect using SDK client to local /mcp (POST + SSE).  ï¿¼
	â€¢ âœ…	examples/smithery-client.ts: connect to https://server.smithery.ai/<pkg>/mcp via StreamableHTTPClientTransport (include config).  ï¿¼
	â€¢ âœ…	examples/spec-workflow.md: stepâ€‘byâ€‘step "run Spec Kit through MCP tools" demo.  ï¿¼
	â€¢ âœ…	Update README with quick start (local and Smithery) and FAQ.

â¸»

Story 12 â€” Tests: unit, integration, smoke, and performance âœ… MOSTLY COMPLETE

Goal: High confidence, automated.

	â€¢ âœ…	Integration tests: start Express on ephemeral port; call POST/GET/DELETE; validate SSE. [31/33 tests passing]
	â€¢ âœ…	JSON-RPC 2.0 compliance tests [All passing]
	â€¢ âœ…	Error handling tests [All passing]
	â€¢ âœ…	Protocol version negotiation tests [All passing]
	â€¢ âš ï¸	Stateful session management tests [2 failing - SDK limitation]
	â€¢ âš ï¸	Unit tests for every tool handler (valid/invalid inputs). [Partial - need more coverage]
	â€¢	"Spec Kit path" tests: simulate specify/plan/tasks flow and verify artifacts are parsed.
	â€¢	Smoke tests in CI: build â†’ run â†’ hit /healthz â†’ basic POST roundtrip.
	â€¢	Perf baseline: run autocannon at 50 rps on POST; ensure p95 < 150ms for trivial tool.
	â€¢	Coverage gate: fail CI < 90% statements.

â¸»

Story 13 â€” CI/CD & release automation âœ…

Goal: Every commit is validated; releases are easy.

	â€¢ âœ…	Add GitHub Actions: ci.yml (install, build, lint, test, coverage artifact).
	â€¢ âœ…	Add release.yml (manual) to publish to NPM on tag.
	â€¢ âœ…	Integrate Changesets or semanticâ€‘release for semver bumps.
	â€¢ âœ…	Generate changelog and GitHub release notes.
	â€¢ âœ…	Cache ~/.npm and node_modules for faster CI.

â¸»

Story 14 â€” Prepare for NPM publishing âœ…

Goal: Package is consumable by anyone.

	â€¢ âœ…	Ensure package.json has "name", "version", "main": "dist/index.js", "types": "dist/index.d.ts", keywords, repository, license.
	â€¢ âœ…	Create src/index.ts with public exports (createServer, tool registrars).
	â€¢ âœ…	Build with tsup to ESM (and, if desired, dual ESM/CJS); verify exports map.
	â€¢ âœ…	Add "files" whitelist (exclude test/source by default).
	â€¢ âœ…	Add README sections: install, usage, config, Smithery notes.  ï¿¼
	â€¢ âœ…	Run npm pack and inspect tarball.
	â€¢ âœ…	Publish dryâ€‘run (if configured) â†’ npm publish.

â¸»

Story 15 â€” Smithery integration & deployment âœ…

Goal: Make it live on Smithery and compatible with the platform.

	â€¢ âœ…	Create smithery.yaml (not json) with runtime: "typescript" configuration per Smithery TypeScript deployment guide.  ï¿¼
	â€¢ âœ…	Configure package.json with build/dev scripts using @smithery/cli.
	â€¢ âœ…	Structure server with default export function createServer({ config }) returning McpServer instance.
	â€¢ âœ…	Add optional configSchema export using Zod for configuration validation.
	â€¢ âœ…	Ensure /mcp implements GET/POST/DELETE exactly per Smithery expectations.  ï¿¼
	â€¢ âœ…	Ensure support for ?config=<base64> query param decoded and validated.  ï¿¼
	â€¢ âœ…	**CRITICAL**: Ensure HTTP transport only - STDIO deprecated September 7, 2025.
	â€¢ âœ…	Consider using ts-smithery-cli approach for simplest migration path.
	â€¢ âœ…	Add "Deploy on Smithery" instructions to README (GitHub integration method).  ï¿¼
	â€¢	Postâ€‘deploy smoke test using Smithery's recommended client flow (Streamable HTTP client).  ï¿¼
	â€¢	Document API key usage where applicable (Smithery registry/SDK).  ï¿¼

â¸»

Story 16 â€” Migration path (if upgrading an existing STDIO server) âœ…

Goal: Provide a crisp path to Streamable HTTP (and optionally maintain compatibility).

	â€¢ âœ…	Capture current STDIO entrypoint and tool registrations; freeze a "before" tag.
	â€¢ âœ…	Create HTTP transport entry (/mcp) alongside STDIO temporarily; verify both work.  ï¿¼
	â€¢ âœ…	Replace server bootstrap to not write to stdout (HTTP is fine; STDIO must not log on stdout).
	â€¢ âœ…	Remove legacy SSE transport if present and document backwards compatibility choices.  ï¿¼
	â€¢ âœ…	Update docs for new connection instructions and note deprecation of STDIO hosting where applicable (per vendor communications).
	â€¢ â³	Remove STDIO once clients have migrated; cut major version; update Smithery deployment type. [Scheduled for Sept 2025]

â¸»

Story 17 â€” Crossâ€‘agent validation (Copilot, Claude Code, Cursor, Gemini)

Goal: Prove it works across the common agent surfaces Spec Kit targets.

	â€¢	Write a lab note for Copilot: how to connect, run Specâ€‘Driven tools, and view streamed output.  ï¿¼
	â€¢	Write a lab note for Claude Code with the same flow.  ï¿¼
	â€¢	Write a lab note for Gemini CLI with the same flow.  ï¿¼
	â€¢	Validate that task numbering and spec artifacts look consistent to all agents (the Spec Kit convention).  ï¿¼
	â€¢	Capture agentâ€‘specific quirks and workarounds in docs/agents.md.

â¸»

Story 18 â€” Observability & diagnostics

Goal: Make it debuggable.

	â€¢	Add request/response logging with correlation ID per session (avoid content logging; log envelopes).
	â€¢	Add â€œdebug modeâ€ flag to include timing and stream event counts.
	â€¢	Add /metrics (Prometheus text format) for basic counters (requests, SSE connections, errors).
	â€¢	Provide LOG_LEVEL env var; default info.

â¸»

Story 19 â€” Hardening & security checks

Goal: Lower risk and prove care.

	â€¢	Dependency scanning: npm audit and (optional) Snyk in CI.
	â€¢	Fuzz minimal JSONâ€‘RPC payloads to ensure 400/422 paths are correct.
	â€¢	Ensure Origin checks enforced and unit tested.  ï¿¼
	â€¢	Redâ€‘team review doc listing auth model and secrets handling.
	â€¢	Add e2e test for Mcp-Session-Id rotation (server invalidates old session â†’ client gets 404 â†’ reâ€‘init).  ï¿¼

â¸»

Story 20 â€” Documentation polish

Goal: Great firstâ€‘time experience.

	â€¢	Expand README with architecture diagram (request flow, SSE stream).
	â€¢	Add a â€œSpecâ€‘Driven Quickstartâ€ section mapping the four phases to the exposed tools.  ï¿¼
	â€¢	Add troubleshooting: common HTTP/SSE pitfalls, protocol version header, Origin errors.  ï¿¼
	â€¢	Add examples section with copyâ€‘paste commands for local & Smithery usage.  ï¿¼

â¸»

Story 21 â€” Release v0.1.0 and beyond

Goal: Ship and iterate safely.

	â€¢	Set version to 0.1.0; create tag and GitHub release.
	â€¢	npm publish; capture URL in README badges.
	â€¢	Register/publish on Smithery and verify the listing + deployment works endâ€‘toâ€‘end.  ï¿¼
	â€¢	Open roadmap issues for future: Python port; advanced resumability; richer auth; multiâ€‘tenant configs.  ï¿¼

â¸»

Story 22 â€” Best Practices & Common Pitfalls Prevention

Goal: Implement research-backed patterns to avoid known issues.

	â€¢	**Session Management**: Implement proper session ID validation (visible ASCII 0x21-0x7E only).
	â€¢	**Error Handling**: Use McpError class with ErrorCode enum for protocol-level errors.
	â€¢	**Stateless vs Stateful**: Document when to use each mode (stateless for serverless, stateful for persistent connections).
	â€¢	**Request ID Collisions**: Ensure new transport instances per request in stateless mode to prevent collisions.
	â€¢	**Browser Compatibility**: Test session management in both Node.js and browser environments.
	â€¢	**Timeout Management**: Handle long-running operations with progress updates to reset 60-second timeout.
	â€¢	**Logging**: All diagnostic output to stderr only, never to stdout (critical for STDIO compatibility).
	â€¢	**TypeScript Config**: Verify module: "NodeNext" and moduleResolution: "NodeNext" in tsconfig.json.
	â€¢	**Version Negotiation**: Handle MCP-Protocol-Version header properly with fallback to "2025-03-26".
	â€¢	**Resource Cleanup**: Use res.on('close') for proper cleanup of per-request resources.
	â€¢	Document all patterns in docs/best-practices.md with code examples.

â¸»

Story 23 â€” Optional: Backwards compatibility with HTTP+SSE 2024â€‘11â€‘05 (legacy)

Goal: Serve older clients during a transition (if needed).

	â€¢	Decide whether to also expose the old SSE endpoint(s) alongside the new MCP endpoint.  ï¿¼
	â€¢	If yes, implement the legacy GET SSE initiation and POST pairing as described in the specâ€™s backwardâ€‘compatibility section.  ï¿¼
	â€¢	Add tests proving both transports operate without message duplication.  ï¿¼
	â€¢	Document sunset schedule; remove legacy in a future major.

â¸»

## Lessons Learned from v0.4.2 Release

### Critical Documentation Issue Discovered

**Problem Identified:** Documentation incorrectly described MCP prompts as user-typed slash commands, causing significant confusion.

**Root Cause:**
- Misunderstood how MCP prompts work vs how Claude Code uses `@` symbol
- README suggested users type `@mcp__dincoder__start_project` to invoke prompts
- Confused MCP protocol's programmatic prompt discovery with user-facing UI

**User Insight:** User correctly identified that `@` in Claude Code is for file attachments, not MCP prompts. This was the key insight that revealed the documentation error.

**What MCP Prompts Actually Are:**
- **Workflow orchestrators** for AI agents, not user commands
- Discovered programmatically via `prompts/list` JSON-RPC call
- Invoked automatically by AI when relevant to user's request
- **Invisible to users** - users just describe goals in natural language

### Documentation Fixes Implemented

1. **README.md Major Rewrite** âœ…
   - **Before:** Section titled "MCP Prompts (Slash Commands)"
   - **After:** Section titled "MCP Prompts (AI Workflow Orchestration)"
   - **Impact:** Removed all incorrect `@` syntax examples
   - **Added:** Clear explanation of programmatic invocation
   - **Added:** Workflow examples showing AI discovers and uses prompts automatically

2. **CLAUDE.md Critical Clarification** âœ…
   - **Added:** Prominent "âš ï¸ MCP Prompts vs Slash Commands" section
   - **Placement:** After "Critical Requirements" for high visibility
   - **Content:**
     - Distinction between MCP prompts, slash commands, and custom commands
     - How MCP prompts work (prompts/list, prompts/get JSON-RPC calls)
     - Example workflow showing AI using prompts programmatically
   - **Impact:** Internal AI agents now understand the distinction

3. **PUBLISH_INSTRUCTIONS.md** âœ…
   - **Created:** Complete npm publishing guide
   - **Sections:** Pre-publish checklist, testing steps, post-publish verification
   - **Value:** Ensures correct publishing process for future releases

4. **CHANGELOG.md** âœ…
   - **Added:** Comprehensive v0.4.1 entry
   - **Documented:** All documentation corrections made
   - **Explained:** The misconception that was fixed
   - **Status:** Package ready to publish to npm

### Lessons Learned

1. **Verify Platform-Specific UI Patterns Early** âš ï¸ CRITICAL
   - Different MCP clients have different UI conventions
   - Claude Code: `@` for files, `/` for native commands, MCP prompts invisible
   - VS Code Copilot: Different integration pattern
   - Lesson: Test documentation against actual platform behavior

2. **MCP Protocol â‰  User Interface**
   - MCP provides programmatic capabilities (tools, prompts, resources)
   - How clients expose these varies widely
   - Prompts are for AI agents, not end users
   - Lesson: Clearly separate protocol features from UI affordances in documentation

3. **Listen to User Confusion**
   - User's question about `@` syntax revealed fundamental documentation flaw
   - Quick validation via web search confirmed the issue
   - Lesson: User confusion often signals documentation accuracy problems

4. **Documentation-Only Releases Are Valid**
   - v0.4.1 is documentation-only, no code changes
   - Still valuable: prevents user confusion and misuse
   - Lesson: Don't hesitate to release for critical documentation fixes

### Key Metrics

- **Version:** 0.4.2 published to npm
- **Tests:** 52/52 tests passing (100% pass rate) - no code changes
- **Files Changed:** 4 documentation files (README.md, CLAUDE.md, CHANGELOG.md, PUBLISH_INSTRUCTIONS.md)
- **Impact:** Critical user experience improvement
- **Publication Status:** âœ… PUBLISHED to npm (v0.4.2)

### What Happened

v0.4.1 was already published 23 hours ago with the OLD documentation. Since npm doesn't allow overwriting published versions, we bumped to v0.4.2 to publish the corrected documentation.

### Next Steps (Post-Publication)

1. âœ… Version bumped to v0.4.2
2. Publishing to npm in progress...
3. Create Git tag after successful publish
4. Push commits and tags to GitHub
5. Verify package on https://www.npmjs.com/package/mcp-dincoder

â¸»

## Lessons Learned from v0.1.7 Release

### Critical Features Delivered

1. **Real Spec Kit Integration** âœ… TRANSFORMATIVE
   - **Achievement**: Transformed from mock implementation to authentic Spec-Driven Development
   - **Implementation**: Created 3 new modules (detector.ts, parser.ts, templates.ts)
   - **Impact**: Now generates real Spec Kit markdown documents that work with GitHub's SDD methodology
   - **Compatibility**: Maintains backward compatibility with JSON format while adding markdown support

2. **CI/CD Pipeline Fixed** âœ…
   - **Issue**: Smoke test failure in CI environment
   - **Fix**: Set PORT=3000 environment variable in CI configuration
   - **Result**: All 33 tests now passing (100% pass rate)

3. **Smithery Deployment Ready** âœ…
   - **Configuration**: smithery.yaml with runtime: "typescript"
   - **Structure**: Default export function for Smithery compatibility
   - **Features**: Base64 config parameter support implemented
   - **Documentation**: Added "Deploy on Smithery" button to README

### Critical Issues Resolved (from v0.1.6)

1. **Tool Naming Validation** âš ï¸ CRITICAL
   - **Issue**: MCP tools with periods in names (e.g., "specify.start") violated the validation pattern `^[a-zA-Z0-9_-]{1,64}$`
   - **Impact**: Complete Claude Desktop integration failure
   - **Fix**: Changed all 15 tool names from periods to underscores (e.g., "specify_start")
   - **Lesson**: Always validate tool names against MCP specification early

2. **External Command Dependencies**
   - **Issue**: specify_start tool attempted to execute external `uvx specify init` command
   - **Impact**: Tool failure in environments without Spec Kit CLI installed
   - **Fix**: Replaced with self-contained file system operations creating .dincoder directory
   - **Lesson**: MCP tools should be self-contained and not rely on external CLI tools

3. **Directory Structure Standardization**
   - **Issue**: Scattered spec files across specs/ directory made navigation difficult
   - **Impact**: Poor developer experience and confusing file organization
   - **Fix**: Consolidated all artifacts under .dincoder/ directory with clear subdirectories
   - **Lesson**: Use a single, well-organized directory for all generated artifacts

4. **STDIO Deprecation Planning**
   - **Issue**: STDIO transport will be discontinued on Smithery by September 7, 2025
   - **Impact**: All servers must migrate to HTTP transport
   - **Fix**: Created comprehensive migration guide (docs/stdio-migration-guide.md)
   - **Benefits**: 20x higher concurrency, lower latency, better resource efficiency
   - **Lesson**: Plan transport migrations well in advance with clear documentation

### Technical Improvements

1. **Natural Language Input Parsing**
   - Added intelligent parsing for specify_describe to accept natural language inputs
   - Strips common prefixes like "/specify", "I want to", etc.
   - Makes tools more user-friendly and forgiving

2. **Error Handling Enhancement**
   - Added actionable next steps in error messages
   - Improved error context with file paths and suggestions
   - Better user guidance when operations fail

3. **Quality Tool Integration**
   - Successfully integrated 6 quality tools (format, lint, test, security_audit, deps_update, license_check)
   - Fixed undefined stderr reference bug in quality.ts
   - All tools now properly handle project path resolution

### Documentation Achievements

1. **Comprehensive Testing Guide**
   - Created TESTING_GUIDE.md covering all 21 tools (15 core + 6 quality)
   - Detailed test procedures for each tool
   - Expected outputs and validation steps

2. **CI/CD Infrastructure**
   - GitHub Actions workflows for CI (ci.yml) and release (release.yml)
   - Automated testing on Node 20.x and 22.x
   - NPM publication workflow with provenance

3. **Migration Documentation**
   - STDIO to HTTP migration guide with timeline
   - Step-by-step migration instructions
   - Common issues and solutions
   - Performance improvement metrics

### Key Metrics

- **Version**: 0.1.7 ready for release
- **Tests**: 33/33 tests passing (100% pass rate)
- **Tools**: 21 total tools (15 core SDD tools + 6 quality tools)
- **Progress**: 17/23 stories complete (74%)
- **Critical Deadline**: STDIO deprecation on September 7, 2025

â¸»

Appendix â€” Minimal file map (for the agent)
	â€¢	src/index.ts (exports)
	â€¢	src/server/createServer.ts (register tools/resources/prompts)
	â€¢	src/http/app.ts (Express app)
	â€¢	src/http/transport.ts (StreamableHTTPServerTransport glue)  ï¿¼
	â€¢	src/tools/specify.ts (Spec Kit tools)  ï¿¼
	â€¢	src/tools/plan.ts
	â€¢	src/tools/tasks.ts
	â€¢	src/tools/quality.ts
	â€¢	src/config/schema.ts (Zod)
	â€¢	src/security/origin.ts (Origin validation)  ï¿¼
	â€¢	src/security/auth.ts
	â€¢	src/logging/logger.ts
	â€¢	specs/000-orchestrator/spec.md (generated)  ï¿¼
	â€¢	specs/000-orchestrator/plan.md (generated)  ï¿¼
	â€¢	specs/000-orchestrator/tasks.md (generated)  ï¿¼
	â€¢	docs/research/spec-kit-notes.md  ï¿¼
	â€¢	docs/refs.md (links to specs/repos)  ï¿¼ ï¿¼ ï¿¼
	â€¢	smithery.yaml (deployment metadata)  ï¿¼

â¸»

Sources consulted (key, authoritative)
	â€¢	MCP Streamable HTTP transport (Protocol Revision 2025-03-26, replaces HTTP+SSE from 2024-11-05).  ï¿¼
	â€¢	Smithery deployments (WebSocket hosting, STDIO deprecation Sept 7, 2025, GitHub integration deployment).  ï¿¼
	â€¢	Model Context Protocol SDKs - TypeScript v1.17.5+ (Streamable HTTP since v1.10.0, April 2025).  ï¿¼
	â€¢	Spec Kit GitHub repo & GitHub blog (commands, crossâ€‘agent focus).  ï¿¼ ï¿¼
	â€¢	YouTube transcript (Spec Kit phases, artifacts, scripts/templates, tasks numbering).
	â€¢	Example implementations: invariantlabs-ai/mcp-streamable-http, ferrants/mcp-streamable-http-typescript-server.

If you want me to generate the repo scaffolding (files + boilerplate code + example tests) directly from this checklist, say the word and Iâ€™ll output a readyâ€‘toâ€‘download project skeleton next.
â¸»

## ğŸ¯ PHASE 1: CORE COMPLETENESS (v0.2.0)

**Goal:** Achieve feature parity with essential Spec Kit workflow for AI coding assistants
**Timeline:** 2 weeks (~1 sprint)
**New Tools:** 7 (constitution_create, clarify_add, clarify_resolve, spec_validate, artifacts_analyze, spec_refine, prereqs_check)
**Total Tools After Phase 1:** 21

â¸»

Story 24 â€” Constitution/Principles Tool â­ CRITICAL

Goal: Enable projects to define principles and constraints that guide all AI-generated artifacts.

Rationale: Without a constitution, specs can drift from project values. Constitution provides guardrails for AI when generating specs, plans, and tasks. Similar to GitHub Spec Kit's `/constitution` command but adapted for MCP context.

Tools to Implement:
	â€¢	constitution_create - Define project principles, constraints, and preferences

Tasks:
	â€¢	Create src/tools/constitution.ts module
	â€¢	Define ConstitutionCreateSchema with Zod:
		â—‹	projectName: string (name of project)
		â—‹	principles: string[] (e.g., "Prefer functional patterns", "Avoid premature optimization")
		â—‹	constraints: string[] (e.g., "Max bundle size: 500KB", "Support Node 20+")
		â—‹	preferences: object with optional fields:
			Â§	libraries?: string[] (e.g., ["React Query over Redux"])
			Â§	patterns?: string[] (e.g., ["Repository pattern for data access"])
			Â§	style?: string (e.g., "Functional > OOP")
		â—‹	workspacePath?: string (optional workspace directory)
	â€¢	Create src/speckit/constitution-template.ts:
		â—‹	Define markdown template for constitution.md
		â—‹	Sections: Project Principles, Technical Constraints, Library Preferences, Code Style
		â—‹	Include examples and reasoning fields
	â€¢	Implement constitutionCreate() function:
		â—‹	Resolve workspace path using resolveWorkspacePath()
		â—‹	Find/create specs directory using findSpecsDirectory()
		â—‹	Create feature directory using createFeatureDirectory()
		â—‹	Generate constitution.md from template with user-provided values
		â—‹	Write to {project}/constitution.md
		â—‹	Return success message with file path
	â€¢	Add tool registration in src/server/createServer.ts:
		â—‹	Register constitution_create tool with schema
		â—‹	Add to tool list
	â€¢	Write unit tests in tests/tools/constitution.test.ts:
		â—‹	Test schema validation
		â—‹	Test constitution generation with various inputs
		â—‹	Test file writing to correct location
		â—‹	Test error handling (invalid workspace, etc.)
	â€¢	Write integration test in tests/integration/constitution-workflow.test.ts:
		â—‹	Test constitution â†’ specify â†’ plan workflow
		â—‹	Verify constitution influences spec generation
	â€¢	Update README.md:
		â—‹	Add constitution_create to tool list
		â—‹	Add usage example showing how to define project principles
		â—‹	Add to workflow guide (Step 0: Define Constitution)
	â€¢	Add constitution.md to .gitignore template (optional, user choice to commit)

Acceptance Criteria:
	â€¢	âœ… Can create constitution.md with structured principles, constraints, and preferences
	â€¢	âœ… Constitution file validates against schema
	â€¢	âœ… File is written to correct specs directory structure
	â€¢	âœ… AI agents can reference constitution when generating specs/plans
	â€¢	âœ… All tests pass with 90%+ coverage
	â€¢	âœ… Documentation updated with examples

â¸»

Story 25 â€” Clarification Tracking â­ CRITICAL

Goal: Provide structured Q&A process for resolving spec ambiguities.

Rationale: Specs often have [NEEDS CLARIFICATION] markers indicating unknowns. Without structured tracking, clarifications get lost in comments or never resolved. This implements GitHub Spec Kit's `/clarify` command for MCP.

Tools to Implement:
	â€¢	clarify_add - Flag ambiguities in specifications
	â€¢	clarify_resolve - Resolve clarifications with structured answers

Tasks:
	â€¢	Create src/tools/clarify.ts module
	â€¢	Define ClarifyAddSchema with Zod:
		â—‹	question: string (the clarification question)
		â—‹	context: string (section of spec that's ambiguous)
		â—‹	options?: string[] (possible resolutions)
		â—‹	specPath?: string (path to spec.md, auto-detected if not provided)
		â—‹	workspacePath?: string
	â€¢	Define ClarifyResolveSchema with Zod:
		â—‹	clarificationId: string (unique ID like CLARIFY-001)
		â—‹	resolution: string (the answer/decision)
		â—‹	rationale?: string (why this resolution was chosen)
		â—‹	workspacePath?: string
	â€¢	Implement clarification storage:
		â—‹	Create .dincoder/clarifications.json for tracking
		â—‹	Schema: { id, question, context, options, status, resolution?, resolvedAt?, addedAt }
		â—‹	Use JSON for structured querying
	â€¢	Implement clarifyAdd():
		â—‹	Generate unique clarification ID (CLARIFY-001, CLARIFY-002, etc.)
		â—‹	Parse spec.md to find existing [NEEDS CLARIFICATION] markers
		â—‹	Store clarification in clarifications.json with status: "pending"
		â—‹	Optionally update spec.md with ID marker: [NEEDS CLARIFICATION: CLARIFY-001]
		â—‹	Return clarification ID and summary
	â€¢	Implement clarifyResolve():
		â—‹	Load clarifications.json
		â—‹	Find clarification by ID
		â—‹	Mark as status: "resolved" with resolution and timestamp
		â—‹	Update spec.md: replace [NEEDS CLARIFICATION: ID] with resolution text
		â—‹	Append resolution to research.md under "Clarifications" section
		â—‹	Git commit with message: "Resolve CLARIFY-001: [question]"
		â—‹	Return success with resolution summary
	â€¢	Add list functionality (optional helper):
		â—‹	clarifyList() to show all pending clarifications
	â€¢	Add tool registration in src/server/createServer.ts
	â€¢	Write unit tests in tests/tools/clarify.test.ts:
		â—‹	Test adding clarifications
		â—‹	Test resolving clarifications
		â—‹	Test ID generation uniqueness
		â—‹	Test spec.md marker insertion/replacement
		â—‹	Test clarifications.json persistence
	â€¢	Write integration test in tests/integration/clarify-workflow.test.ts:
		â—‹	Test full workflow: add â†’ list â†’ resolve
		â—‹	Test spec.md updates
		â—‹	Test research.md logging
	â€¢	Update README.md:
		â—‹	Add clarify_add and clarify_resolve to tool list
		â—‹	Add clarification workflow example
		â—‹	Update workflow guide with clarification step

Acceptance Criteria:
	â€¢	âœ… Can flag ambiguities in specs with structured questions
	â€¢	âœ… Clarifications tracked in version-controlled JSON file
	â€¢	âœ… Can resolve with structured answers
	â€¢	âœ… Resolutions automatically update spec.md and research.md
	â€¢	âœ… Unique ID generation prevents collisions
	â€¢	âœ… All tests pass with 90%+ coverage
	â€¢	âœ… Documentation includes workflow examples

â¸»

Story 26 â€” Spec Validation & Quality Gates â­ CRITICAL

Goal: Automated quality checks for specifications before moving to plan/tasks phases.

Rationale: Incomplete or ambiguous specs lead to wasted implementation effort. Quality gates catch issues early. Implements GitHub Spec Kit's `/analyze` command with focus on spec validation for AI workflows.

Tools to Implement:
	â€¢	spec_validate - Check specification quality
	â€¢	artifacts_analyze - Verify spec/plan/tasks consistency

Tasks:
	â€¢	Create src/tools/validate.ts module
	â€¢	Define SpecValidateSchema with Zod:
		â—‹	checks: object with boolean flags:
			Â§	completeness?: boolean (all required sections present)
			Â§	acceptanceCriteria?: boolean (every feature has testable criteria)
			Â§	clarifications?: boolean (no unresolved [NEEDS CLARIFICATION])
			Â§	prematureImplementation?: boolean (no HOW in WHAT sections)
		â—‹	specPath?: string (auto-detect if not provided)
		â—‹	workspacePath?: string
	â€¢	Define ArtifactsAnalyzeSchema with Zod:
		â—‹	artifacts?: ('spec' | 'plan' | 'tasks')[] (which to analyze, default: all)
		â—‹	workspacePath?: string
	â€¢	Implement validation rules in src/speckit/validators.ts:
		â—‹	checkCompleteness(spec): Verify required sections (Goals, Acceptance, Edge Cases, Research)
		â—‹	checkAcceptanceCriteria(spec): Ensure every feature has "when/then" testable criteria
		â—‹	checkClarifications(spec): Find unresolved [NEEDS CLARIFICATION] markers
		â—‹	checkPrematureImplementation(spec): Detect HOW details in WHAT sections (flag code blocks, library names in goals)
	â€¢	Implement specValidate():
		â—‹	Load and parse spec.md
		â—‹	Run selected validation checks
		â—‹	Generate validation report with warnings and errors:
			Â§	errors: array of { rule, message, location }
			Â§	warnings: array of { rule, message, suggestion }
			Â§	passed: boolean (no errors)
		â—‹	Return structured report
	â€¢	Implement artifactsAnalyze():
		â—‹	Load spec.md, plan.md, tasks.md
		â—‹	Check spec vs plan consistency:
			Â§	All spec goals covered in plan
			Â§	No plan components not in spec
		â—‹	Check plan vs tasks consistency:
			Â§	All plan components have tasks
			Â§	No orphaned tasks (not in plan)
		â—‹	Detect missing tasks for planned features
		â—‹	Return consistency report with issues
	â€¢	Add tool registration in src/server/createServer.ts
	â€¢	Write unit tests in tests/tools/validate.test.ts:
		â—‹	Test each validation rule independently
		â—‹	Test completeness check with missing sections
		â—‹	Test clarification detection
		â—‹	Test premature implementation detection
		â—‹	Test artifacts consistency checking
	â€¢	Write integration test in tests/integration/validation-workflow.test.ts:
		â—‹	Test validation with problematic spec
		â—‹	Test validation pass with good spec
		â—‹	Test artifacts analysis with mismatched plan/tasks
	â€¢	Update README.md:
		â—‹	Add spec_validate and artifacts_analyze to tool list
		â—‹	Add validation examples showing error detection
		â—‹	Update workflow guide with validation gates

Acceptance Criteria:
	â€¢	âœ… Detects missing sections in specs
	â€¢	âœ… Flags unresolved clarifications
	â€¢	âœ… Catches premature implementation details (HOW in WHAT)
	â€¢	âœ… Validates cross-artifact consistency (spec â†” plan â†” tasks)
	â€¢	âœ… Provides actionable error messages with suggestions
	â€¢	âœ… Returns structured reports (JSON) for AI parsing
	â€¢	âœ… All tests pass with 90%+ coverage
	â€¢	âœ… Documentation includes validation workflow

â¸»

Story 27 â€” Spec Refinement/Evolution

Goal: Enable iterative improvement of specifications without losing history.

Rationale: Specs are living documents that evolve as understanding deepens. Need structured way to update without corrupting structure or losing decision context. Git commits track changes.

Tools to Implement:
	â€¢	spec_refine - Update existing specs with tracked changes

Tasks:
	â€¢	Create src/tools/refine.ts module
	â€¢	Define SpecRefineSchema with Zod:
		â—‹	section: enum ('goals' | 'acceptance' | 'edge-cases' | 'research' | 'full')
		â—‹	changes: string (markdown describing updates)
		â—‹	reason: string (why this refinement is needed)
		â—‹	specPath?: string (auto-detect if not provided)
		â—‹	workspacePath?: string
	â€¢	Implement markdown section parser in src/speckit/parser.ts:
		â—‹	parseSpecSections(spec): Extract section boundaries (line ranges)
		â—‹	getSectionContent(spec, section): Get specific section text
		â—‹	setSectionContent(spec, section, newContent): Replace section
	â€¢	Implement specRefine():
		â—‹	Load existing spec.md
		â—‹	Parse to identify section boundaries
		â—‹	Apply changes to specified section (or full spec if section='full')
		â—‹	Validate updated spec structure (ensure headers intact)
		â—‹	Append changelog entry to research.md:
			Â§	"## Spec Refinement: [date]"
			Â§	"**Section:** [section]"
			Â§	"**Reason:** [reason]"
			Â§	"**Changes:** [changes]"
		â—‹	Write updated spec.md
		â—‹	Git commit with message: "refine: [section] - [reason]"
		â—‹	Return success with change summary
	â€¢	Add versioning support (optional):
		â—‹	Before refining, create snapshot: spec.v1.md, spec.v2.md
		â—‹	Maintain spec.md as latest version
		â—‹	Store version metadata in .dincoder/spec-versions.json
	â€¢	Add tool registration in src/server/createServer.ts
	â€¢	Write unit tests in tests/tools/refine.test.ts:
		â—‹	Test section parsing
		â—‹	Test section updates
		â—‹	Test full spec updates
		â—‹	Test research.md logging
		â—‹	Test git commit creation
	â€¢	Write integration test in tests/integration/refine-workflow.test.ts:
		â—‹	Test iterative refinement (multiple refines)
		â—‹	Test version history preservation
		â—‹	Test spec structure integrity after refinement
	â€¢	Update README.md:
		â—‹	Add spec_refine to tool list
		â—‹	Add refinement workflow example
		â—‹	Show how to iterate on specs

Acceptance Criteria:
	â€¢	âœ… Can update specific spec sections without affecting others
	â€¢	âœ… Preserves git history of all changes
	â€¢	âœ… Logs refinement reasons in research.md
	â€¢	âœ… Doesn't corrupt spec structure (headers, sections)
	â€¢	âœ… Optional versioning creates snapshots
	â€¢	âœ… All tests pass with 90%+ coverage
	â€¢	âœ… Documentation shows refinement workflow

â¸»

Story 28 â€” Prerequisites Check

Goal: Verify development environment has required tools and versions.

Rationale: Prevents "works on my machine" issues. Validates environment before spec execution. Similar to GitHub Spec Kit's `specify check` command but extensible for custom prerequisites.

Tools to Implement:
	â€¢	prereqs_check - Verify system requirements

Tasks:
	â€¢	Create src/tools/prereqs.ts module
	â€¢	Define PrereqsCheckSchema with Zod:
		â—‹	checkFor: object with optional fields:
			Â§	node?: string (version requirement, e.g., ">=20")
			Â§	npm?: boolean (check availability)
			Â§	git?: boolean (check availability)
			Â§	docker?: boolean (check availability)
			Â§	customCommands?: string[] (e.g., ["kubectl", "terraform"])
		â—‹	fix?: boolean (attempt auto-fix if possible, default: false)
		â—‹	workspacePath?: string
	â€¢	Implement version checkers in src/tools/prereqs.ts:
		â—‹	checkNodeVersion(requirement): Run `node --version`, parse and compare
		â—‹	checkCommandAvailable(command): Run `which [command]` or `command -v`
		â—‹	parseVersionRequirement(req): Parse ">=20", "^18.0.0", etc.
		â—‹	compareVersions(actual, required): Semantic version comparison
	â€¢	Implement prereqsCheck():
		â—‹	Run checks for specified prerequisites
		â—‹	Collect results: { tool, required, actual, passed }
		â—‹	Generate report:
			Â§	passed: boolean (all checks passed)
			Â§	results: array of check results
			Â§	suggestions: array of fix suggestions for failures
		â—‹	If fix=true, attempt auto-fixes:
			Â§	Suggest nvm/fnm for Node version issues
			Â§	Suggest brew/apt for missing tools (platform-specific)
		â—‹	Return structured report
	â€¢	Add common prerequisite templates:
		â—‹	webAppPrereqs: Node, npm, git
		â—‹	dockerizedAppPrereqs: Node, npm, git, docker
		â—‹	kubernetesAppPrereqs: Node, npm, git, docker, kubectl
	â€¢	Add tool registration in src/server/createServer.ts
	â€¢	Write unit tests in tests/tools/prereqs.test.ts:
		â—‹	Test version parsing and comparison
		â—‹	Test command availability checking
		â—‹	Test report generation
		â—‹	Test suggestion generation for failures
	â€¢	Write integration test in tests/integration/prereqs-workflow.test.ts:
		â—‹	Test prerequisite check with current environment
		â—‹	Test handling of missing prerequisites
	â€¢	Update README.md:
		â—‹	Add prereqs_check to tool list
		â—‹	Add prerequisite checking examples
		â—‹	Add to workflow guide (Step 0: Verify Prerequisites)

Acceptance Criteria:
	â€¢	âœ… Detects missing or outdated tools
	â€¢	âœ… Supports version requirement syntax (>=, ^, ~)
	â€¢	âœ… Provides clear error messages for failures
	â€¢	âœ… Suggests fixes when possible (install commands)
	â€¢	âœ… Supports custom prerequisite checks
	â€¢	âœ… All tests pass with 90%+ coverage
	â€¢	âœ… Documentation includes prerequisite examples

â¸»

## Phase 1 Summary

**Stories Completed:** 5 new stories (24-28)
**Tools Added:** 7 new tools
**Total Tools:** 21 (14 existing + 7 new)
**Estimated Effort:** ~35-40 tasks
**Timeline:** 2 weeks (1 sprint)

**Tools by Category After Phase 1:**
- **Workflow Setup (3):** constitution_create, prereqs_check, specify_start
- **Specification (3):** specify_describe, clarify_add, clarify_resolve
- **Validation (3):** spec_validate, artifacts_analyze, spec_refine
- **Planning (1):** plan_create
- **Tasks (2):** tasks_generate, tasks_tick
- **Supporting (3):** artifacts_read, research_append, git_create_branch
- **Quality (6):** quality_format, quality_lint, quality_test, quality_security_audit, quality_deps_update, quality_license_check

**Key Achievements:**
- âœ… Complete Spec Kit workflow parity (constitution, clarify, validate)
- âœ… Quality gates prevent incomplete specs from progressing
- âœ… Iterative refinement supports living documents
- âœ… Environment validation prevents setup issues
- âœ… All critical gaps from analysis addressed

**Next Phase:** Phase 2 - Workflow Enhancement (tasks visualization, filtering, batch operations, search, statistics)

---

## Phase 2: Workflow Enhancement (v0.3.0) ğŸš€

**Goal:** Improve AI workflow efficiency with advanced task management capabilities

**Stories:** 29-33 (5 new stories)
**Tools Added:** 5 new tools (+5 â†’ 26 total)
**Estimated Effort:** ~50 tasks
**Timeline:** ~2 weeks (1 sprint)

**Value Proposition:**
- Phase 1 gave us **spec quality** (validation, refinement, clarification)
- Phase 2 gives us **task efficiency** (visualization, filtering, batch operations)
- AI agents can work 5x faster on large projects (50+ tasks)

---

Story 29 â€” Task Visualization & Dependency Graphs ğŸ”„

Goal: Enable AI to understand task relationships and execution order through visual dependency graphs.

Why it matters:
- AI agents can identify which tasks are blocked by dependencies
- Prevents implementing tasks out of order (e.g., tests before implementation)
- Visualizes project structure at a glance using Mermaid diagrams
- Essential for complex projects with 20+ interdependent tasks

Tasks:
	â€¢	Create src/speckit/taskParser.ts module:
		â—‹	Parse tasks.md into structured task objects
		â—‹	Extract task metadata (ID, status, description, dependencies)
		â—‹	Support optional metadata format: `(phase: setup, type: backend, depends: T001)`
		â—‹	Handle legacy tasks.md without metadata gracefully
	â€¢	Implement dependency detection:
		â—‹	Parse "depends on T001" or "depends: T001" syntax
		â—‹	Support multiple dependencies: "depends: T001, T002"
		â—‹	Build dependency graph data structure (adjacency list)
		â—‹	Detect circular dependencies and raise errors
	â€¢	Create src/tools/visualize.ts with tasks_visualize tool:
		â—‹	Define Zod schema (workspacePath, format, includeCompleted)
		â—‹	Implement tool handler calling visualization logic
		â—‹	Return Mermaid diagram as markdown code block
	â€¢	Implement Mermaid graph generation:
		â—‹	Generate flowchart LR (left-to-right) syntax
		â—‹	Create task boxes with IDs and descriptions
		â—‹	Add dependency arrows between tasks
		â—‹	Apply status-based styling (pending=gray, in-progress=yellow, completed=green)
	â€¢	Add advanced visualization features:
		â—‹	Support filtering (hide completed tasks)
		â—‹	Add phase grouping (subgraphs for setup/core/polish)
		â—‹	Calculate critical path highlighting
		â—‹	Add estimated completion time based on dependencies
	â€¢	Support multiple output formats:
		â—‹	mermaid (default - renders in markdown)
		â—‹	graphviz (DOT format for advanced tools)
		â—‹	ascii-tree (terminal-friendly text output)
	â€¢	Write comprehensive tests:
		â—‹	Test dependency parsing edge cases
		â—‹	Test circular dependency detection
		â—‹	Test Mermaid syntax generation
		â—‹	Test format conversion (mermaid, graphviz, ascii)
	â€¢	Update documentation:
		â—‹	Add tasks_visualize to README tool list
		â—‹	Add visualization workflow examples
		â—‹	Include sample Mermaid diagrams

Acceptance Criteria:
	â€¢	âœ… Parses tasks.md with and without metadata
	â€¢	âœ… Detects circular dependencies and fails gracefully
	â€¢	âœ… Generates valid Mermaid flowchart syntax
	â€¢	âœ… Supports 3 output formats (mermaid, graphviz, ascii)
	â€¢	âœ… Colors tasks by status (pending/in-progress/completed)
	â€¢	âœ… All tests pass with 90%+ coverage
	â€¢	âœ… Documentation includes visualization examples

â¸»

Story 30 â€” Task Filtering & Smart Queries ğŸ”

Goal: Help AI find relevant tasks quickly in large backlogs through intelligent filtering.

Why it matters:
- Large projects accumulate 100+ tasks across multiple phases
- AI needs to answer "what can I do NOW" without reading entire backlog
- Reduces cognitive load and improves task selection accuracy
- Essential for parallel development (frontend/backend team members)

Tasks:
	â€¢	Extend src/speckit/taskParser.ts:
		â—‹	Extract phase metadata ("phase: setup" â†’ setup)
		â—‹	Extract type metadata ("type: frontend" â†’ frontend)
		â—‹	Extract tags metadata ("tags: auth, api" â†’ ["auth", "api"])
		â—‹	Support comma-separated and space-separated formats
	â€¢	Create src/tools/filter.ts with tasks_filter tool:
		â—‹	Define Zod schema with filter parameters
		â—‹	Support status filter (pending, in_progress, completed, all)
		â—‹	Support phase filter (setup, core, polish, custom)
		â—‹	Support type filter (frontend, backend, test, docs, custom)
		â—‹	Support blocker filter (blocked, unblocked, all)
		â—‹	Support tag filter (array of tags, AND/OR logic)
	â€¢	Implement filter logic:
		â—‹	Parse tasks.md into structured objects
		â—‹	Apply status filtering
		â—‹	Apply phase filtering with wildcard support
		â—‹	Apply type filtering with wildcard support
		â—‹	Calculate blocked status from dependencies
		â—‹	Apply tag filtering with AND/OR logic
	â€¢	Add sorting options:
		â—‹	Sort by priority (metadata: priority: high/medium/low)
		â—‹	Sort by dependencies (topological sort - unblocked first)
		â—‹	Sort by created date (if available in metadata)
		â—‹	Sort by estimated effort (metadata: effort: 1-5)
	â€¢	Implement smart presets:
		â—‹	"next" preset: unblocked, pending tasks sorted by priority
		â—‹	"frontend" preset: type=frontend, unblocked
		â—‹	"ready" preset: unblocked, pending, high priority
		â—‹	"cleanup" preset: low priority, polish phase
	â€¢	Return filtered results:
		â—‹	Format as markdown task list (copy-paste ready)
		â—‹	Include summary header (X tasks found, Y blocked)
		â—‹	Show metadata for each task
		â—‹	Optionally include reasons why tasks were excluded
	â€¢	Write comprehensive tests:
		â—‹	Test each filter type independently
		â—‹	Test filter combinations (status + phase + type)
		â—‹	Test smart presets
		â—‹	Test sorting algorithms
		â—‹	Test edge cases (empty results, all tasks filtered)
	â€¢	Update documentation:
		â—‹	Add tasks_filter to README tool list
		â—‹	Add filtering workflow examples
		â—‹	Document metadata format for tasks
		â—‹	Show smart preset usage

Acceptance Criteria:
	â€¢	âœ… Filters by status, phase, type, blockers, tags
	â€¢	âœ… Supports AND/OR logic for complex queries
	â€¢	âœ… Includes 4+ smart presets for common workflows
	â€¢	âœ… Returns markdown-formatted results
	â€¢	âœ… Handles empty results gracefully
	â€¢	âœ… All tests pass with 90%+ coverage
	â€¢	âœ… Documentation includes filter query examples

â¸»

Story 31 â€” Batch Task Operations âš¡

Goal: Reduce tool call overhead for AI agents through batch task completion.

Why it matters:
- Completing 10 related tasks currently requires 10 separate tasks_tick calls
- Batch operations save time and reduce error surface area
- Natural workflow when implementing multiple related tasks together
- Improves AI agent efficiency by 10x for bulk operations

Tasks:
	â€¢	Create src/tools/batch.ts with tasks_tick_range tool:
		â—‹	Define Zod schema accepting task ID array or range
		â—‹	Support array format: ["T001", "T003", "T007"]
		â—‹	Support range format: "T001-T005" (inclusive)
		â—‹	Support mixed format: ["T001-T005", "T010", "T012-T015"]
		â—‹	Add optional completion notes (per-task or shared)
	â€¢	Implement batch validation:
		â—‹	Verify all task IDs exist in tasks.md
		â—‹	Check tasks are in pending status (can't complete already-done tasks)
		â—‹	Validate range syntax (T001-T005 format)
		â—‹	Expand ranges to individual task IDs
	â€¢	Implement atomic batch completion:
		â—‹	Mark all specified tasks as completed ([x])
		â—‹	Update tasks.md file with all changes
		â—‹	Add completion timestamp if metadata is present
		â—‹	Preserve task order and formatting
	â€¢	Handle partial failures gracefully:
		â—‹	If task T003 doesn't exist, complete T001, T002, skip T003, continue
		â—‹	Return detailed report: X succeeded, Y failed, Z skipped
		â—‹	Include failure reasons (not found, already completed, invalid status)
		â—‹	Optionally support strict mode (fail all if any task invalid)
	â€¢	Add rollback on validation errors:
		â—‹	If range syntax is invalid, fail immediately without changes
		â—‹	If file write fails, revert any in-memory changes
		â—‹	Return clear error message with suggested fixes
	â€¢	Generate summary report:
		â—‹	List completed task IDs with descriptions
		â—‹	Show statistics (X completed, Y failed, Z skipped)
		â—‹	Include completion percentage (overall progress)
		â—‹	Return updated tasks.md content or path
	â€¢	Write comprehensive tests:
		â—‹	Test array format batch completion
		â—‹	Test range format batch completion
		â—‹	Test mixed format batch completion
		â—‹	Test partial failure handling
		â—‹	Test rollback on validation errors
		â—‹	Test strict vs lenient mode
	â€¢	Update documentation:
		â—‹	Add tasks_tick_range to README tool list
		â—‹	Add batch operation workflow examples
		â—‹	Show range syntax and array syntax
		â—‹	Document error handling behavior

Acceptance Criteria:
	â€¢	âœ… Supports array, range, and mixed formats
	â€¢	âœ… Handles partial failures gracefully (lenient mode)
	â€¢	âœ… Supports strict mode (all-or-nothing)
	â€¢	âœ… Returns detailed completion report
	â€¢	âœ… Rolls back on validation errors
	â€¢	âœ… All tests pass with 90%+ coverage
	â€¢	âœ… Documentation includes batch operation examples

â¸»

Story 32 â€” Task Search & Discovery ğŸ”

Goal: Enable keyword-based task discovery in large projects through full-text search.

Why it matters:
- Projects with 50+ tasks need search functionality
- AI needs to find "authentication tasks" or "database migration tasks" quickly
- Grep-style search through task descriptions and metadata
- Essential for understanding existing work and avoiding duplicates

Tasks:
	â€¢	Create src/tools/search.ts with tasks_search tool:
		â—‹	Define Zod schema (query, searchFields, caseSensitive, fuzzy)
		â—‹	Support regex patterns for advanced queries
		â—‹	Support plain text for simple searches
		â—‹	Add optional result limit (default: 10, max: 100)
	â€¢	Implement full-text search:
		â—‹	Search task descriptions by default
		â—‹	Optionally search metadata (phase, type, tags)
		â—‹	Support case-sensitive and case-insensitive modes
		â—‹	Use JavaScript regex for pattern matching
	â€¢	Add fuzzy matching:
		â—‹	Implement Levenshtein distance for typo tolerance
		â—‹	Support fuzzy threshold (0-100% similarity)
		â—‹	Rank results by similarity score
		â—‹	Highlight approximate matches
	â€¢	Search across multiple fields:
		â—‹	searchFields: ['description'] (default)
		â—‹	searchFields: ['description', 'phase', 'type', 'tags']
		â—‹	searchFields: ['all'] (search everything)
		â—‹	Combine results from multiple fields
	â€¢	Highlight matching text:
		â—‹	Wrap matches in markdown bold: **match**
		â—‹	Show context (20 chars before/after match)
		â—‹	Truncate long descriptions with ellipsis
		â—‹	Support multiple matches per task
	â€¢	Return results with context:
		â—‹	Include task ID, status, description
		â—‹	Show surrounding tasks (previous/next task)
		â—‹	Include relevance score (0-100%)
		â—‹	Add metadata if available
	â€¢	Add relevance scoring:
		â—‹	Exact matches: 100%
		â—‹	Starts with query: 90%
		â—‹	Contains query: 70%
		â—‹	Fuzzy match: 50-70% (based on similarity)
		â—‹	Sort results by relevance
	â€¢	Write comprehensive tests:
		â—‹	Test exact match search
		â—‹	Test regex pattern search
		â—‹	Test fuzzy matching with typos
		â—‹	Test multi-field search
		â—‹	Test result limiting
		â—‹	Test edge cases (no matches, special characters)
	â€¢	Update documentation:
		â—‹	Add tasks_search to README tool list
		â—‹	Add search workflow examples
		â—‹	Show regex pattern examples
		â—‹	Document fuzzy matching behavior

Acceptance Criteria:
	â€¢	âœ… Supports plain text and regex queries
	â€¢	âœ… Implements fuzzy matching for typo tolerance
	â€¢	âœ… Searches across task descriptions and metadata
	â€¢	âœ… Highlights matching text in results
	â€¢	âœ… Ranks results by relevance score
	â€¢	âœ… All tests pass with 90%+ coverage
	â€¢	âœ… Documentation includes search query examples

â¸»

Story 33 â€” Task Statistics & Progress Tracking ğŸ“Š

Goal: Give AI agents quick project overview without parsing full tasks.md file.

Why it matters:
- "How many tasks are left?" is a frequent question from users
- AI can report progress without manual counting
- Helps with estimation and timeline planning
- Provides metrics for team velocity tracking

Tasks:
	â€¢	Create src/tools/stats.ts with tasks_stats tool:
		â—‹	Define Zod schema (workspacePath, groupBy, timeRange)
		â—‹	Support grouping by status, phase, type, priority
		â—‹	Support time range filtering (last 7 days, last 30 days, all)
		â—‹	Return structured statistics object
	â€¢	Calculate basic statistics:
		â—‹	Total tasks count
		â—‹	Pending tasks count
		â—‹	In-progress tasks count
		â—‹	Completed tasks count
		â—‹	Completion percentage (completed / total * 100)
	â€¢	Break down by phase:
		â—‹	Count tasks per phase (setup, core, polish, custom)
		â—‹	Calculate completion % per phase
		â—‹	Identify bottleneck phases (low completion %)
		â—‹	Return sorted by phase order
	â€¢	Break down by type:
		â—‹	Count tasks per type (frontend, backend, test, docs, custom)
		â—‹	Calculate completion % per type
		â—‹	Identify work distribution (frontend: 50%, backend: 30%)
		â—‹	Return sorted by task count
	â€¢	Calculate velocity metrics:
		â—‹	Parse completion timestamps from metadata
		â—‹	Calculate tasks completed per day (average)
		â—‹	Calculate tasks completed in last 7 days
		â—‹	Calculate tasks completed in last 30 days
	â€¢	Estimate completion date:
		â—‹	Based on average velocity (tasks/day)
		â—‹	Remaining tasks / velocity = days until completion
		â—‹	Return estimated completion date (YYYY-MM-DD)
		â—‹	Add confidence interval (Â±X days)
	â€¢	Support time range filtering:
		â—‹	Filter by creation date (if available in metadata)
		â—‹	Filter by completion date (if available in metadata)
		â—‹	Calculate statistics for specific time windows
		â—‹	Compare current vs previous period
	â€¢	Format statistics report:
		â—‹	Return as JSON object (machine-readable)
		â—‹	Optionally format as markdown table (human-readable)
		â—‹	Include visual progress bars (â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘ 50%)
		â—‹	Add trend indicators (â†‘ velocity increasing)
	â€¢	Write comprehensive tests:
		â—‹	Test basic statistics calculations
		â—‹	Test grouping by phase, type, priority
		â—‹	Test velocity calculations
		â—‹	Test completion date estimation
		â—‹	Test time range filtering
		â—‹	Test edge cases (no tasks, all completed)
	â€¢	Update documentation:
		â—‹	Add tasks_stats to README tool list
		â—‹	Add statistics workflow examples
		â—‹	Show interpretation of metrics
		â—‹	Document velocity calculation methodology

Acceptance Criteria:
	â€¢	âœ… Calculates total, pending, in-progress, completed counts
	â€¢	âœ… Breaks down statistics by phase and type
	â€¢	âœ… Calculates velocity (tasks/day) from timestamps
	â€¢	âœ… Estimates completion date based on velocity
	â€¢	âœ… Supports time range filtering
	â€¢	âœ… Returns JSON and markdown formatted results
	â€¢	âœ… All tests pass with 90%+ coverage
	â€¢	âœ… Documentation includes statistics interpretation guide

â¸»

## Phase 2 Summary

**Stories Completed:** 5 new stories (29-33)
**Tools Added:** 5 new tools
**Total Tools:** 26 (21 existing + 5 new)
**Estimated Effort:** ~50 tasks
**Timeline:** 2 weeks (1 sprint)

**Tools by Category After Phase 2:**
- **Workflow Setup (3):** constitution_create, prereqs_check, specify_start
- **Specification (3):** specify_describe, clarify_add, clarify_resolve
- **Validation (3):** spec_validate, artifacts_analyze, spec_refine
- **Planning (1):** plan_create
- **Tasks (7):** tasks_generate, tasks_tick, tasks_visualize, tasks_filter, tasks_tick_range, tasks_search, tasks_stats
- **Supporting (3):** artifacts_read, research_append, git_create_branch
- **Quality (6):** quality_format, quality_lint, quality_test, quality_security_audit, quality_deps_update, quality_license_check

**Key Achievements:**
- âœ… Task dependency visualization with Mermaid diagrams
- âœ… Intelligent task filtering for large projects (50+ tasks)
- âœ… Batch task completion (10x efficiency improvement)
- âœ… Full-text task search with fuzzy matching
- âœ… Comprehensive progress statistics and velocity tracking

â¸»

## Phase 3: Integration & Discovery (v0.4.0 - v0.7.0)

**Goal:** Make DinCoder workflows discoverable and accessible across all platforms

**Reference:** See [INTEGRATION_STRATEGY.md](INTEGRATION_STRATEGY.md) for complete implementation details

â¸»

Story 34 â€” MCP Prompts (Strategy A - Universal) âœ…

Goal: Create MCP prompts that become slash commands in all MCP clients

Why it matters:
- Zero-configuration discovery across all platforms
- Built-in workflow guidance for new users
- Eliminates need to memorize tool names
- Works universally (Claude Code, VS Code, Codex, Cursor)

Tasks:
	â€¢ âœ… Create src/server/prompts.ts module
	â€¢ âœ… Implement registerPrompts() function
	â€¢ âœ… Add 7 workflow prompts:
		â—‹ âœ… start_project - Initialize new spec-driven project
		â—‹ âœ… create_spec - Create feature specification
		â—‹ âœ… generate_plan - Generate implementation plan
		â—‹ âœ… create_tasks - Break down into actionable tasks
		â—‹ âœ… review_progress - Generate progress report
		â—‹ âœ… validate_spec - Check specification quality
		â—‹ âœ… next_tasks - Show next actionable tasks
	â€¢ âœ… Each prompt includes comprehensive workflow instructions
	â€¢ âœ… Enable prompts capability in createServer.ts
	â€¢ âœ… Update README.md with MCP Prompts section
	â€¢ âœ… Update CLAUDE.md with prompts reference
	â€¢ âœ… Write tests for prompt registration
	â€¢ âœ… Document cross-platform slash command formats

Acceptance Criteria:
	â€¢ âœ… 7 prompts registered and discoverable
	â€¢ âœ… Each prompt returns GetPromptResult with workflow messages
	â€¢ âœ… Arguments use Zod schemas for validation
	â€¢ âœ… Works in Claude Code (/mcp__dincoder__<prompt>)
	â€¢ âœ… Works in VS Code Copilot (/mcp.dincoder.<prompt>)
	â€¢ âœ… Works in OpenAI Codex (/mcp.dincoder.<prompt>)
	â€¢ âœ… Works in Cursor (/mcp__dincoder__<prompt>)
	â€¢ âœ… All tests pass
	â€¢ âœ… Documentation complete

â¸»

Story 35 â€” Claude Code Plugin (Strategy B)

Goal: Create bundled Claude Code plugin with commands, agents, and MCP server config

Why it matters:
- Best long-term experience for Claude Code users
- Bundles slash commands, agents, and documentation
- One-command installation
- Optimized for Claude Code workflows

Tasks:
	â€¢	Create new repository: dincoder-plugin
	â€¢	Create .claude-plugin/plugin.json:
		â—‹	Define plugin metadata (name, version, description)
		â—‹	Configure MCP server connection
		â—‹	List included commands and agents
	â€¢	Create commands/ directory:
		â—‹	spec.md - Create/refine specification
		â—‹	plan.md - Generate implementation plan
		â—‹	tasks.md - Create actionable tasks
		â—‹	progress.md - Show progress report
		â—‹	validate.md - Check specification quality
		â—‹	next.md - Show next tasks
	â€¢	Create agents/ directory:
		â—‹	spec-writer.md - Specification writing agent
		â—‹	plan-architect.md - Planning agent
		â—‹	task-manager.md - Task management agent
	â€¢	Create CLAUDE.md with plugin usage guide
	â€¢	Create .mcp.json with server configuration
	â€¢	Write comprehensive README.md
	â€¢	Test installation: claude plugin install dincoder
	â€¢	Publish to Claude Code plugin registry

Acceptance Criteria:
	â€¢	Plugin installable via Claude CLI
	â€¢	All commands work as slash commands
	â€¢	Agents are discoverable in Claude Code
	â€¢	MCP server auto-configured
	â€¢	Documentation complete

â¸»

Story 36 â€” VS Code & Codex Integration (Strategies C+D)

Goal: Document VS Code Copilot and OpenAI Codex integration patterns

Why it matters:
- Large user base uses VS Code and Codex
- Different configuration patterns than Claude Code
- Need clear setup instructions

Tasks:
	â€¢	Create docs/integration/vscode.md:
		â—‹	Document .vscode/mcp.json configuration
		â—‹	Show workspace-level setup
		â—‹	Document slash command format (/mcp.dincoder.<prompt>)
		â—‹	Add troubleshooting section
	â€¢	Create docs/integration/codex.md:
		â—‹	Document ~/.codex/config.toml setup
		â—‹	Show MCP server configuration
		â—‹	Document CLI usage patterns
		â—‹	Add troubleshooting section
	â€¢	Update README.md with VS Code section
	â€¢	Update README.md with Codex section
	â€¢	Create video tutorial for VS Code setup
	â€¢	Create video tutorial for Codex setup
	â€¢	Test with VS Code Copilot
	â€¢	Test with OpenAI Codex

Acceptance Criteria:
	â€¢	VS Code integration documented
	â€¢	Codex integration documented
	â€¢	README includes setup guides
	â€¢	Video tutorials published
	â€¢	Tested in both environments

â¸»

Story 37 â€” Project Templates (Strategy E)

Goal: Create starter templates for common project types

Why it matters:
- Faster onboarding for new projects
- Best practices built-in
- Reduces initial configuration

Tasks:
	â€¢	Create templates/ repository
	â€¢	Create web-app template:
		â—‹	Pre-configured constitution.md
		â—‹	Sample spec.md structure
		â—‹	Common architectural patterns
		â—‹	Technology stack recommendations
	â€¢	Create api-service template:
		â—‹	API-focused constitution
		â—‹	OpenAPI/REST patterns
		â—‹	Testing strategies
	â€¢	Create mobile-app template:
		â—‹	Mobile-specific constitution
		â—‹	Platform considerations
		â—‹	Deployment patterns
	â€¢	Create cli-tool template:
		â—‹	CLI-focused patterns
		â—‹	Command structure
		â—‹	Distribution strategy
	â€¢	Document template usage in README
	â€¢	Create template customization guide
	â€¢	Test template instantiation
	â€¢	Publish templates to GitHub

Acceptance Criteria:
	â€¢	4 templates created (web, api, mobile, cli)
	â€¢	Each includes constitution, spec, plan templates
	â€¢	Documentation complete
	â€¢	Templates tested and working

â¸»

Story 38 â€” Integration Testing & Documentation

Goal: Comprehensive testing across all integration strategies

Why it matters:
- Ensure consistent experience across platforms
- Catch platform-specific issues
- Maintain quality as platforms evolve

Tasks:
	â€¢	Test Strategy A (MCP Prompts):
		â—‹	Test in Claude Code
		â—‹	Test in VS Code Copilot
		â—‹	Test in OpenAI Codex
		â—‹	Test in Cursor
		â—‹	Document any platform quirks
	â€¢	Test Strategy B (Claude Plugin):
		â—‹	Test plugin installation
		â—‹	Test all commands
		â—‹	Test all agents
		â—‹	Verify MCP server connection
	â€¢	Test Strategy C+D (VS Code/Codex):
		â—‹	Test configuration files
		â—‹	Test slash commands
		â—‹	Test in different workspace setups
	â€¢	Test Strategy E (Templates):
		â—‹	Test template instantiation
		â—‹	Test customization workflows
		â—‹	Verify all templates work
	â€¢	Create integration test matrix:
		â—‹	Platform Ã— Feature grid
		â—‹	Document known limitations
		â—‹	Track platform version compatibility
	â€¢	Update INTEGRATION_STRATEGY.md with test results
	â€¢	Create troubleshooting guide
	â€¢	Document platform-specific tips

Acceptance Criteria:
	â€¢	All strategies tested on all platforms
	â€¢	Test matrix documented
	â€¢	Troubleshooting guide complete
	â€¢	Known issues documented

â¸»

## Phase 3 Summary

**Stories Completed:** 1/5 (Story 34 complete)
**Stories Remaining:** 4 (Stories 35-38)
**Prompts Added:** 7 workflow prompts
**Total Features:** 26 tools + 7 prompts = 33
**Estimated Effort:** ~100 tasks across 4 stories
**Timeline:** 3-4 weeks (2 sprints)

**Integration Strategies:**
- âœ… **Strategy A (Universal):** MCP Prompts - COMPLETE (v0.4.0)
- ğŸ“‹ **Strategy B (Claude Code):** Plugin - PLANNED (v0.5.0)
- ğŸ“‹ **Strategy C+D (VS Code/Codex):** Documentation - PLANNED (v0.6.0)
- ğŸ“‹ **Strategy E (Templates):** Project starters - PLANNED (v0.7.0)

**Key Achievements (v0.4.0):**
- âœ… 7 workflow prompts with built-in guidance
- âœ… Auto-discovery across all MCP clients
- âœ… Cross-platform slash commands
- âœ… Zero-configuration integration
- âœ… Published to npm as mcp-dincoder@0.4.0

**Next Milestone:** v0.5.0 - Claude Code Plugin (Strategy B)
- âœ… AI agents can navigate large task backlogs 5x faster

**Next Phase:** Phase 3 - Advanced Features (contracts, templates, metrics, lint)

---

## Appendix A: Deferred or Removed Roadmap Items

- **diagram_generate** â€” Removed after Spec Kit research confirmed there is no dedicated diagram command. AI assistants already embed Mermaid/PlantUML directly in markdown, so we now include diagram examples in the constitution template instead of adding a tool.
- **idea_capture** â€” Dropped because `specify_describe` accepts both terse prompts and detailed briefs, matching Spec Kitâ€™s workflow. A separate idea-capture tool would duplicate existing functionality.
- **project_bootstrap** â€” Removed since orchestration belongs to the AI assistant. MCP tools remain atomic (constitution â†’ specify â†’ plan â†’ tasks) just like Spec Kit; wrapping them in a single bootstrap tool would reduce flexibility.

## Appendix B: Research References

- `docs/SPEC_KIT_RESEARCH.md` â€” Consolidated findings from GitHub Spec Kit, MCP protocol updates, and Smithery requirements.
- MCP Streamable HTTP (Protocol Revision 2025-03-26) â€” single `/mcp` endpoint with POST/GET/DELETE, session headers, and protocol negotiation.
- Smithery deployment guidance â€” STDIO deprecation (September 7, 2025), Streamable HTTP hosting, `?config=<base64>` support.
- Spec Kit workflow â€” `/specify`, `/plan`, `/tasks` gated flow; clarifications via `[NEEDS CLARIFICATION]`.
- SDK support â€” `@modelcontextprotocol/sdk` â‰¥ 1.17.5 provides Streamable HTTP client/server transports for Node.js.
